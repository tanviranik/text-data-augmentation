{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import sklearn\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = '../data/input/imperatives/ground_truth/'\n",
    "OUTPUT_DIR = '../data/'\n",
    "MODEL_DIR = '../models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_file = os.path.join(INPUT_DIR, 'imperatives_binary_data.csv')\n",
    "df_data_raw = pd.read_csv(ip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Find a sturdy piece of cardboard in the form o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stand up for yourself</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fix out priorities together in a meeting  a co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Make one last snowball for the penguin's head</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Look for the internet venue you will use for y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2319</th>\n",
       "      <td>it's a Finnish documentary but it has all thes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>yeah  because you took time when you had your ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2321</th>\n",
       "      <td>oh  come on  you're kidding  right.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2322</th>\n",
       "      <td>You see.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>Do you think we need to do more.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2324 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     Find a sturdy piece of cardboard in the form o...      1\n",
       "1                                 Stand up for yourself      1\n",
       "2     Fix out priorities together in a meeting  a co...      1\n",
       "3         Make one last snowball for the penguin's head      1\n",
       "4     Look for the internet venue you will use for y...      1\n",
       "...                                                 ...    ...\n",
       "2319  it's a Finnish documentary but it has all thes...      0\n",
       "2320  yeah  because you took time when you had your ...      0\n",
       "2321                oh  come on  you're kidding  right.      0\n",
       "2322                                           You see.      0\n",
       "2323                   Do you think we need to do more.      0\n",
       "\n",
       "[2324 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = []\n",
    "    # antonyms = []\n",
    "\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for l in syn.lemmas():\n",
    "            synonyms.append(l.name())\n",
    "                \n",
    "    return list(set(synonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def replace_synonym(sentence, word):\n",
    "    \n",
    "    augmented_sentences = []\n",
    "    augmented_sentences.append(sentence)\n",
    "    \n",
    "    sentence_words = sentence.split(' ')\n",
    "    \n",
    "    if word in sentence_words:\n",
    "        \n",
    "        synonyms = get_synonyms(word)\n",
    "    \n",
    "        for synonym in synonyms:\n",
    "            reg_ex = r'\\b'+word+r'\\b'\n",
    "            new_setence = re.sub(reg_ex, synonym, sentence)\n",
    "        \n",
    "            augmented_sentences.append(new_setence)\n",
    "        \n",
    "    return augmented_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a good phone', 'This constitute a good phone', 'This exist a good phone', 'This embody a good phone', 'This be a good phone', 'This represent a good phone', 'This follow a good phone', 'This comprise a good phone', 'This equal a good phone', 'This personify a good phone', 'This cost a good phone', 'This live a good phone', 'This make_up a good phone']\n"
     ]
    }
   ],
   "source": [
    "sentence = 'This is a good phone'\n",
    "word = 'is'\n",
    "print(replace_synonym(sentence, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_augmentation(sentence):\n",
    "    \n",
    "    sentences = []\n",
    "    \n",
    "    words = sentence.split(' ')\n",
    "    \n",
    "    for word in words:\n",
    "        # print('---------------------\\n', word)\n",
    "        new_sentences = replace_synonym(sentence, word)\n",
    "        # print(new_sentences)\n",
    "        sentences.extend(new_sentences)\n",
    "        \n",
    "    return list(set(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_augmentation_withoutstopwords(sentence):\n",
    "    \n",
    "    sentences = []\n",
    "    \n",
    "    words = sentence.split(' ')\n",
    "    \n",
    "    for word in words:\n",
    "        # print('---------------------\\n', word)\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_sentences = replace_synonym(sentence, word)\n",
    "            # print(new_sentences)\n",
    "            sentences.extend(new_sentences)\n",
    "        \n",
    "    return list(set(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a in_effect phone', 'This is a good sound', 'This is a goodness phone', 'This is a skillful phone', 'This is a good earphone', 'This is a adept phone', 'This is a good phone', 'This is a honest phone', 'This is a good earpiece', 'This is a proficient phone', 'This is a dependable phone', 'This is a near phone', 'This is a honorable phone', 'This is a trade_good phone', 'This is a good telephone_set', 'This is a good speech_sound', 'This is a dear phone', 'This is a upright phone', 'This is a sound phone', 'This is a respectable phone', 'This is a soundly phone', 'This is a full phone', 'This is a safe phone', 'This is a secure phone', 'This is a salutary phone', 'This is a thoroughly phone', 'This is a good headphone', 'This is a estimable phone', 'This is a just phone', 'This is a serious phone', 'This is a good ring', 'This is a beneficial phone', 'This is a well phone', 'This is a good telephone', 'This is a expert phone', 'This is a ripe phone', 'This is a effective phone', 'This is a in_force phone', 'This is a good call', 'This is a commodity phone', 'This is a unspoiled phone', 'This is a good call_up', 'This is a undecomposed phone', 'This is a unspoilt phone', 'This is a right phone', 'This is a practiced phone', 'This is a skilful phone']\n"
     ]
    }
   ],
   "source": [
    "sentence = 'This is a good phone'\n",
    "print(synonym_augmentation_withoutstopwords(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imperative = df_data_raw.loc[df_data_raw['label'] == 1]\n",
    "df_nonimperative = df_data_raw.loc[df_data_raw['label'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmented_dataframe(sentence, label):\n",
    "    \n",
    "    augmented_sentences = synonym_augmentation_withoutstopwords(sentence)\n",
    "    labels = [label] * len(augmented_sentences)\n",
    "    \n",
    "    df = pd.DataFrame(list(zip(augmented_sentences, labels)), columns=['text', 'label'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Find a sturdy piece of cardboard in the form o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stand up for yourself</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fix out priorities together in a meeting  a co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Make one last snowball for the penguin's head</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Look for the internet venue you will use for y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Find a sturdy piece of cardboard in the form o...      1\n",
       "1                              Stand up for yourself      1\n",
       "2  Fix out priorities together in a meeting  a co...      1\n",
       "3      Make one last snowball for the penguin's head      1\n",
       "4  Look for the internet venue you will use for y...      1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imperative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug_imperative = pd.DataFrame(columns=['text', 'label'])\n",
    "for index, row in df_imperative.iterrows():\n",
    "    \n",
    "    sentence = row['text']\n",
    "    label = row['label']\n",
    "    \n",
    "    df = get_augmented_dataframe(sentence, label)\n",
    "    \n",
    "    df_aug_imperative = pd.concat([df_aug_imperative, df], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 66115 entries, 0 to 11\n",
      "Data columns (total 2 columns):\n",
      "text     66115 non-null object\n",
      "label    66115 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_aug_imperative.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 66115})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_aug_imperative['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Find a sturdy piece of cardboard in the frame ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Find a hardy piece of cardboard in the form of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Find a sturdy piece of cardboard in the soma o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Find a sturdy piece of cardboard in the form o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Find a sturdy piece of cardboard in the class ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  Find a sturdy piece of cardboard in the frame ...     1\n",
       "1  Find a hardy piece of cardboard in the form of...     1\n",
       "2  Find a sturdy piece of cardboard in the soma o...     1\n",
       "3  Find a sturdy piece of cardboard in the form o...     1\n",
       "4  Find a sturdy piece of cardboard in the class ...     1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aug_imperative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug_nonimperative = pd.DataFrame(columns=['text', 'label'])\n",
    "for index, row in df_nonimperative.iterrows():\n",
    "    \n",
    "    sentence = row['text']\n",
    "    label = row['label']\n",
    "    \n",
    "    df = get_augmented_dataframe(sentence, label)\n",
    "    \n",
    "    df_aug_nonimperative = pd.concat([df_aug_nonimperative, df], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 58764})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_aug_nonimperative['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 58764 entries, 0 to 63\n",
      "Data columns (total 2 columns):\n",
      "text     58764 non-null object\n",
      "label    58764 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_aug_nonimperative.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A cockroach will endure nine days without it’s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A cockroach will live nine sidereal_day withou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A cockroach will lively nine days without it’s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A cockroach will live ix days without it’s hea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A cockroach will springy nine days without it’...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  A cockroach will endure nine days without it’s...     0\n",
       "1  A cockroach will live nine sidereal_day withou...     0\n",
       "2  A cockroach will lively nine days without it’s...     0\n",
       "3  A cockroach will live ix days without it’s hea...     0\n",
       "4  A cockroach will springy nine days without it’...     0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aug_nonimperative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.concat([df_aug_nonimperative, df_aug_imperative], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_file = os.path.join(INPUT_DIR, 'imperatives_binary_synonym_aug.csv')\n",
    "df_data.to_csv(ip_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 58764, 1: 66115})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_data['text']\n",
    "label = df_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train_text, data_test_text, label_train, label_test = train_test_split(data, label, test_size=0.20, \n",
    "                                                                  random_state=0, stratify=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data split Counter({1: 52892, 0: 47011})\n",
      "Testing Data split Counter({1: 13223, 0: 11753})\n"
     ]
    }
   ],
   "source": [
    "print('Training Data split', Counter(label_train))\n",
    "print('Testing Data split', Counter(label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_train = pd.DataFrame(list(zip(data_train_text, label_train)), columns=['text', 'label'])\n",
    "df_data_test = pd.DataFrame(list(zip(data_test_text, label_test)), columns=['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fix out priorities together in a meeting  a co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and smell at one of those  you get more than o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hmmm  she says  Then why are you calling here ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's like hold_out backwards.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Differentiate age  genders  and skill levels t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Fix out priorities together in a meeting  a co...      1\n",
       "1  and smell at one of those  you get more than o...      0\n",
       "2  Hmmm  she says  Then why are you calling here ...      0\n",
       "3                      It's like hold_out backwards.      0\n",
       "4  Differentiate age  genders  and skill levels t...      1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    # print(text, end ='')\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W',' ', text)\n",
    "    text = re.sub(' \\d+', ' ', text)\n",
    "    text = re.sub(r'\\s+',' ', text)\n",
    "        \n",
    "    words = text.split(' ')\n",
    "    words = [w.strip() for w in words if w not in stopwords.words('english')]\n",
    "    \n",
    "    text = ' '.join(words)\n",
    "    text = text.strip()\n",
    "        \n",
    "    # print(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df_data):\n",
    "    df_data['processed_text'] = df_data['text'].apply(lambda x: preprocess_text(x))\n",
    "    df_data.drop(df_data[df_data['processed_text'] == ''].index, inplace=True)\n",
    "    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train before cleaning (99903, 2)\n",
      "Train after cleaning (99853, 3)\n",
      "Test before cleaning (24976, 2)\n",
      "Test after cleaning (24957, 3)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess train & test data frame\n",
    "print('Train before cleaning', df_data_train.shape)\n",
    "df_data_train = preprocess_df(df_data_train)\n",
    "print('Train after cleaning', df_data_train.shape)\n",
    "\n",
    "\n",
    "print('Test before cleaning', df_data_test.shape)\n",
    "df_data_test = preprocess_df(df_data_test)\n",
    "print('Test after cleaning', df_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fix out priorities together in a meeting  a co...</td>\n",
       "      <td>1</td>\n",
       "      <td>fix priorities together meeting couple weeks s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and smell at one of those  you get more than o...</td>\n",
       "      <td>0</td>\n",
       "      <td>smell one get one frequency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hmmm  she says  Then why are you calling here ...</td>\n",
       "      <td>0</td>\n",
       "      <td>hmmm says calling travel past broad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's like hold_out backwards.</td>\n",
       "      <td>0</td>\n",
       "      <td>like hold_out backwards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Differentiate age  genders  and skill levels t...</td>\n",
       "      <td>1</td>\n",
       "      <td>differentiate age genders skill levels determi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  Fix out priorities together in a meeting  a co...      1   \n",
       "1  and smell at one of those  you get more than o...      0   \n",
       "2  Hmmm  she says  Then why are you calling here ...      0   \n",
       "3                      It's like hold_out backwards.      0   \n",
       "4  Differentiate age  genders  and skill levels t...      1   \n",
       "\n",
       "                                      processed_text  \n",
       "0  fix priorities together meeting couple weeks s...  \n",
       "1                        smell one get one frequency  \n",
       "2                hmmm says calling travel past broad  \n",
       "3                            like hold_out backwards  \n",
       "4  differentiate age genders skill levels determi...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Corpus using only train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Length  99853\n"
     ]
    }
   ],
   "source": [
    "corpus = df_data_train['text'].values\n",
    "print('Corpus Length ', len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "## Use Bag of Words Vectorizer for encoding`\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization of Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data train: (99853, 14490)\n"
     ]
    }
   ],
   "source": [
    "data_train = vectorizer.transform(df_data_train['text'])\n",
    "print('Shape of the data train:',data_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train = np.array(df_data_train['label'])\n",
    "label_train = label_train.reshape((len(label_train), 1))\n",
    "label_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data train: (24957, 14490)\n"
     ]
    }
   ],
   "source": [
    "data_test = vectorizer.transform(df_data_test['text'])\n",
    "print('Shape of the data train:',data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_test = np.array(df_data_test['label'])\n",
    "label_test = label_test.reshape((len(label_test), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with poly (3) kernel - no stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/talat/anaconda3/envs/sentgen/lib/python3.5/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Run Logistic Regression\n",
    "estimator = SVC(kernel='poly', degree=3)\n",
    "estimator.fit(data_train, label_train)\n",
    "predictions = estimator.predict(data_test)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 0.9488123543772315\n",
      "Test Accuracy 0.9449833041819049\n",
      "F1 macro Score:  0.9449259221238242\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94     16073\n",
      "           1       0.90      1.00      0.95     15372\n",
      "\n",
      "    accuracy                           0.94     31445\n",
      "   macro avg       0.95      0.95      0.94     31445\n",
      "weighted avg       0.95      0.94      0.94     31445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "## Accuracy Measure\n",
    "print('Train Accuracy', estimator.score(data_train, label_train))\n",
    "print('Test Accuracy', estimator.score(data_test, label_test))\n",
    "\n",
    "# F1\n",
    "f1_measure = f1_score(label_test, predictions, average='macro')\n",
    "print('F1 macro Score: ', f1_measure)\n",
    "\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = MODEL_DIR + 'svm/' + 'model_svm_poly3_synonym_aug.pkl'\n",
    "with open(model_file, 'wb') as f_op:\n",
    "    pkl.dump(estimator, f_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with linear kernel - no stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/talat/anaconda3/envs/sentgen/lib/python3.5/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Run Logistic Regression\n",
    "estimator = SVC(kernel='linear')\n",
    "estimator.fit(data_train, label_train)\n",
    "predictions = estimator.predict(data_test)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 0.9956536108078876\n",
      "Test Accuracy 0.9912249068397644\n",
      "F1 macro Score:  0.9911904864036325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     11739\n",
      "           1       0.99      0.99      0.99     13218\n",
      "\n",
      "    accuracy                           0.99     24957\n",
      "   macro avg       0.99      0.99      0.99     24957\n",
      "weighted avg       0.99      0.99      0.99     24957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "## Accuracy Measure\n",
    "print('Train Accuracy', estimator.score(data_train, label_train))\n",
    "print('Test Accuracy', estimator.score(data_test, label_test))\n",
    "\n",
    "# F1\n",
    "f1_measure = f1_score(label_test, predictions, average='macro')\n",
    "print('F1 macro Score: ', f1_measure)\n",
    "\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = MODEL_DIR + 'svm/' + 'model_svm_linear_synonym_aug.pkl'\n",
    "with open(model_file, 'wb') as f_op:\n",
    "    pkl.dump(estimator, f_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM - Vanilla - no stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 2, 78, 228, 5, 6, 1463, 4369, 2, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 2, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 2, 2, 349, 2637, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 2, 5, 2, 656, 245, 2350, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 2, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "       list([1, 4, 2, 2, 33, 2804, 4, 2040, 432, 111, 153, 103, 4, 1494, 13, 70, 131, 67, 11, 61, 2, 744, 35, 3715, 761, 61, 2, 452, 2, 4, 985, 7, 2, 59, 166, 4, 105, 216, 1239, 41, 1797, 9, 15, 7, 35, 744, 2413, 31, 8, 4, 687, 23, 4, 2, 2, 6, 3693, 42, 38, 39, 121, 59, 456, 10, 10, 7, 265, 12, 575, 111, 153, 159, 59, 16, 1447, 21, 25, 586, 482, 39, 4, 96, 59, 716, 12, 4, 172, 65, 9, 579, 11, 2, 4, 1615, 5, 2, 7, 2, 17, 13, 2, 12, 19, 6, 464, 31, 314, 11, 2, 6, 719, 605, 11, 8, 202, 27, 310, 4, 3772, 3501, 8, 2722, 58, 10, 10, 537, 2116, 180, 40, 14, 413, 173, 7, 263, 112, 37, 152, 377, 4, 537, 263, 846, 579, 178, 54, 75, 71, 476, 36, 413, 263, 2504, 182, 5, 17, 75, 2306, 922, 36, 279, 131, 2895, 17, 2867, 42, 17, 35, 921, 2, 192, 5, 1219, 3890, 19, 2, 217, 4122, 1710, 537, 2, 1236, 5, 736, 10, 10, 61, 403, 9, 2, 40, 61, 4494, 5, 27, 4494, 159, 90, 263, 2311, 4319, 309, 8, 178, 5, 82, 4319, 4, 65, 15, 2, 145, 143, 2, 12, 2, 537, 746, 537, 537, 15, 2, 4, 2, 594, 7, 2, 94, 2, 3987, 2, 11, 2, 4, 538, 7, 1795, 246, 2, 9, 2, 11, 635, 14, 9, 51, 408, 12, 94, 318, 1382, 12, 47, 6, 2683, 936, 5, 2, 2, 19, 49, 7, 4, 1885, 2, 1118, 25, 80, 126, 842, 10, 10, 2, 2, 4726, 27, 4494, 11, 1550, 3633, 159, 27, 341, 29, 2733, 19, 4185, 173, 7, 90, 2, 8, 30, 11, 4, 1784, 86, 1117, 8, 3261, 46, 11, 2, 21, 29, 9, 2841, 23, 4, 1010, 2, 793, 6, 2, 1386, 1830, 10, 10, 246, 50, 9, 6, 2750, 1944, 746, 90, 29, 2, 8, 124, 4, 882, 4, 882, 496, 27, 2, 2213, 537, 121, 127, 1219, 130, 5, 29, 494, 8, 124, 4, 882, 496, 4, 341, 7, 27, 846, 10, 10, 29, 9, 1906, 8, 97, 6, 236, 2, 1311, 8, 4, 2, 7, 31, 7, 2, 91, 2, 3987, 70, 4, 882, 30, 579, 42, 9, 12, 32, 11, 537, 10, 10, 11, 14, 65, 44, 537, 75, 2, 1775, 3353, 2, 1846, 4, 2, 7, 154, 5, 4, 518, 53, 2, 2, 7, 3211, 882, 11, 399, 38, 75, 257, 3807, 19, 2, 17, 29, 456, 4, 65, 7, 27, 205, 113, 10, 10, 2, 4, 2, 2, 9, 242, 4, 91, 1202, 2, 5, 2070, 307, 22, 7, 2, 126, 93, 40, 2, 13, 188, 1076, 3222, 19, 4, 2, 7, 2348, 537, 23, 53, 537, 21, 82, 40, 2, 13, 2, 14, 280, 13, 219, 4, 2, 431, 758, 859, 4, 953, 1052, 2, 7, 2, 5, 94, 40, 25, 238, 60, 2, 4, 2, 804, 2, 7, 4, 2, 132, 8, 67, 6, 22, 15, 9, 283, 8, 2, 14, 31, 9, 242, 955, 48, 25, 279, 2, 23, 12, 1685, 195, 25, 238, 60, 796, 2, 4, 671, 7, 2804, 5, 4, 559, 154, 888, 7, 726, 50, 26, 49, 2, 15, 566, 30, 579, 21, 64, 2574]),\n",
       "       list([1, 249, 1323, 7, 61, 113, 10, 10, 13, 1637, 14, 20, 56, 33, 2401, 18, 457, 88, 13, 2626, 1400, 45, 3171, 13, 70, 79, 49, 706, 919, 13, 16, 355, 340, 355, 1696, 96, 143, 4, 22, 32, 289, 7, 61, 369, 71, 2359, 5, 13, 16, 131, 2073, 249, 114, 249, 229, 249, 20, 13, 28, 126, 110, 13, 473, 8, 569, 61, 419, 56, 429, 6, 1513, 18, 35, 534, 95, 474, 570, 5, 25, 124, 138, 88, 12, 421, 1543, 52, 725, 2, 61, 419, 11, 13, 1571, 15, 1543, 20, 11, 4, 2, 5, 296, 12, 3524, 5, 15, 421, 128, 74, 233, 334, 207, 126, 224, 12, 562, 298, 2167, 1272, 7, 2601, 5, 516, 988, 43, 8, 79, 120, 15, 595, 13, 784, 25, 3171, 18, 165, 170, 143, 19, 14, 5, 2, 6, 226, 251, 7, 61, 113])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "batch_size = 32\n",
    "N = len(dg.columns[1:])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(2000, embed_dim,input_length = X.shape[1]))\n",
    "model.add(LSTM(lstm_out))\n",
    "model.add(Dense(N,activation='softmax'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/talat/anaconda3/envs/sentgen/lib/python3.5/site-packages/keras_preprocessing/text.py:180: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93659, 91) (93659, 2)\n",
      "(31220, 91) (31220, 2)\n"
     ]
    }
   ],
   "source": [
    "max_fatures = 30000\n",
    "tokenizer = Tokenizer(nb_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(result['Reviews'].values)\n",
    "X1 = tokenizer.texts_to_sequences(result['Reviews'].values)\n",
    "X1 = pad_sequences(X1)\n",
    "Y1 = pd.get_dummies(result['Positivity']).values\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(X1,Y1, random_state = 42)\n",
    "print(X1_train.shape,Y1_train.shape)\n",
    "print(X1_test.shape,Y1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[7, 3, 3, 4, 4, 9, 7, 1, 7]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "# define the document\n",
    "text = 'The quick brown fox jumped over the lazy dog.'\n",
    "# estimate the size of the vocabulary\n",
    "words = set(text_to_word_sequence(text))\n",
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "# integer encode the document\n",
    "result = one_hot(text, round(vocab_size*1.3))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[6, 4, 1, 2, 7, 5, 6, 2, 6]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import hashing_trick\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "# define the document\n",
    "text = 'The quick brown fox jumped over the lazy dog.'\n",
    "# estimate the size of the vocabulary\n",
    "words = set(text_to_word_sequence(text))\n",
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "# integer encode the document\n",
    "result = hashing_trick(text, round(vocab_size*1.3), hash_function='md5')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentgen",
   "language": "python",
   "name": "sentgen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
